# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/05_data/01_data_catalog.html

strokeData:
  type: pandas.CSVDataSet
  filepath: data/01_raw/strokeData.csv

strokeData_limited:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strokeData_limited.csv

strokeData_renamed:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strokeData_renamed.csv

strokeData_missing:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strokeData_missing.csv

strokeData_rebase:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strokeData_rebase.csv

strokeData_cleaned:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strokeData_cleaned.csv

strokeData_encoded:
  type: pandas.CSVDataSet
  filepath: data/03_primary/strokeData_encoded.csv

X_train:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/X_train.csv

X_test:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/X_test.csv

y_train:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/y_train.csv

y_test:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/y_test.csv

df_train:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/df_train.csv

df_test:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/df_test.csv

model_input:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/model_input.pq
  layer: model_input

pycaret_AdaBoost:
  type: pickle.PickleDataSet
  filepath: data/06_models/pycaret_AdaBoost.pickle
  versioned: true

pycaret_random_forest:
  type: pickle.PickleDataSet
  filepath: data/06_models/pycaret_random_forest.pickle
  versioned: true

pycaret_Light_GBM:
  type: pickle.PickleDataSet
  filepath: data/06_models/pycaret_Light_GBM.pickle
  versioned: true